{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) fashion mnist training set shape\n"
     ]
    }
   ],
   "source": [
    "#Data unpacking block\n",
    "from dataset_unpacking_utility import prepare_dataset_mat, prepare_dataset_fashion_mnist, prepare_dataset_mnist\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepare_dataset_mnist()\n",
    "print(X_train.shape, 'fashion mnist training set shape')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=32 : dim_representation=2 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 13s 220us/sample - loss: 4.0651 - recon_error: 1.1823 - val_loss: 3.6758 - val_recon_error: 1.0097\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 12s 207us/sample - loss: 3.2124 - recon_error: 0.8809 - val_loss: 2.9184 - val_recon_error: 0.7932\n",
      "Model training Complete\n",
      "Model saved to: dataset_0_weights_test_ndim_2_filters_32.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=32 : dim_representation=10 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 14s 225us/sample - loss: 4.6925 - recon_error: 1.3694 - val_loss: 4.3533 - val_recon_error: 1.2428\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 12s 207us/sample - loss: 3.6031 - recon_error: 1.0334 - val_loss: 3.3056 - val_recon_error: 0.9612\n",
      "Model training Complete\n",
      "Model saved to: dataset_0_weights_test_ndim_10_filters_32.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=32 : dim_representation=20 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 14s 232us/sample - loss: 4.9213 - recon_error: 1.5032 - val_loss: 4.5501 - val_recon_error: 1.4275\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 13s 209us/sample - loss: 3.6186 - recon_error: 1.1599 - val_loss: 3.2714 - val_recon_error: 1.0932\n",
      "Model training Complete\n",
      "Model saved to: dataset_0_weights_test_ndim_20_filters_32.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=32 : dim_representation=100 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 16s 267us/sample - loss: 4.6878 - recon_error: 1.6310 - val_loss: 3.7113 - val_recon_error: 1.2962\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 15s 243us/sample - loss: 3.0776 - recon_error: 1.1696 - val_loss: 2.8170 - val_recon_error: 1.0787\n",
      "Model training Complete\n",
      "Model saved to: dataset_0_weights_test_ndim_100_filters_32.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=64 : dim_representation=2 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 22s 367us/sample - loss: 5.7092 - recon_error: 1.9433 - val_loss: 4.6678 - val_recon_error: 1.6994\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 20s 334us/sample - loss: 3.8474 - recon_error: 1.5102 - val_loss: 3.6204 - val_recon_error: 1.4823\n",
      "Model training Complete\n",
      "Model saved to: dataset_0_weights_test_ndim_2_filters_64.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=64 : dim_representation=10 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 63s 1ms/sample - loss: 4.6796 - recon_error: 1.5156 - val_loss: 3.8678 - val_recon_error: 1.3509\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 20s 339us/sample - loss: 2.8692 - recon_error: 1.1365 - val_loss: 2.4392 - val_recon_error: 1.0569\n",
      "Model training Complete\n",
      "Model saved to: dataset_0_weights_test_ndim_10_filters_64.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=64 : dim_representation=20 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 23s 382us/sample - loss: 4.8010 - recon_error: 1.5341 - val_loss: 3.6314 - val_recon_error: 1.0651\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 21s 347us/sample - loss: 2.9515 - recon_error: 0.9690 - val_loss: 2.7067 - val_recon_error: 0.8700\n",
      "Model training Complete\n",
      "Model saved to: dataset_0_weights_test_ndim_20_filters_64.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=64 : dim_representation=100 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 27s 445us/sample - loss: 3.5551 - recon_error: 1.2289 - val_loss: 2.5522 - val_recon_error: 1.0272\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 24s 405us/sample - loss: 2.0500 - recon_error: 1.0352 - val_loss: 1.8295 - val_recon_error: 0.9992\n",
      "Model training Complete\n",
      "Model saved to: dataset_0_weights_test_ndim_100_filters_64.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=128 : dim_representation=2 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 47s 781us/sample - loss: 3.2418 - recon_error: 1.0738 - val_loss: 2.2173 - val_recon_error: 0.9187\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 44s 733us/sample - loss: 1.6577 - recon_error: 0.9768 - val_loss: 1.4195 - val_recon_error: 0.9857\n",
      "Model training Complete\n",
      "Model saved to: dataset_0_weights_test_ndim_2_filters_128.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=128 : dim_representation=10 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 47s 783us/sample - loss: 2.3896 - recon_error: 0.7659 - val_loss: 1.6048 - val_recon_error: 0.7229\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 45s 758us/sample - loss: 1.3203 - recon_error: 0.7880 - val_loss: 1.1310 - val_recon_error: 0.8304\n",
      "Model training Complete\n",
      "Model saved to: dataset_0_weights_test_ndim_10_filters_128.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=128 : dim_representation=20 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 48s 803us/sample - loss: 4.1935 - recon_error: 1.6752 - val_loss: 2.9781 - val_recon_error: 1.4918\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 46s 765us/sample - loss: 2.2304 - recon_error: 1.2579 - val_loss: 1.6400 - val_recon_error: 1.0816\n",
      "Model training Complete\n",
      "Model saved to: dataset_0_weights_test_ndim_20_filters_128.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=128 : dim_representation=100 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 55s 909us/sample - loss: 2.9765 - recon_error: 1.3893 - val_loss: 1.9820 - val_recon_error: 1.2054\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 52s 866us/sample - loss: 1.7753 - recon_error: 1.2267 - val_loss: 1.6342 - val_recon_error: 1.1691\n",
      "Model training Complete\n",
      "Model saved to: dataset_0_weights_test_ndim_100_filters_128.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=32 : dim_representation=2 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 17s 278us/sample - loss: 2.9111 - recon_error: 0.7001 - val_loss: 2.4586 - val_recon_error: 0.7079\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 14s 236us/sample - loss: 2.0330 - recon_error: 0.6497 - val_loss: 1.8533 - val_recon_error: 0.6500\n",
      "Model training Complete\n",
      "Model saved to: dataset_1_weights_test_ndim_2_filters_32.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=32 : dim_representation=10 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 17s 282us/sample - loss: 4.1760 - recon_error: 0.8396 - val_loss: 3.7432 - val_recon_error: 0.7583\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 14s 236us/sample - loss: 3.2197 - recon_error: 0.7655 - val_loss: 2.9421 - val_recon_error: 0.7740\n",
      "Model training Complete\n",
      "Model saved to: dataset_1_weights_test_ndim_10_filters_32.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=32 : dim_representation=20 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 17s 288us/sample - loss: 3.3780 - recon_error: 0.7040 - val_loss: 2.7681 - val_recon_error: 0.6637\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 14s 239us/sample - loss: 2.1287 - recon_error: 0.5177 - val_loss: 1.8252 - val_recon_error: 0.4618\n",
      "Model training Complete\n",
      "Model saved to: dataset_1_weights_test_ndim_20_filters_32.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=32 : dim_representation=100 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 19s 324us/sample - loss: 3.2161 - recon_error: 0.6744 - val_loss: 2.1446 - val_recon_error: 0.4986\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 17s 280us/sample - loss: 1.6472 - recon_error: 0.4228 - val_loss: 1.3768 - val_recon_error: 0.3905\n",
      "Model training Complete\n",
      "Model saved to: dataset_1_weights_test_ndim_100_filters_32.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=64 : dim_representation=2 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 25s 421us/sample - loss: 3.4792 - recon_error: 0.8059 - val_loss: 2.7686 - val_recon_error: 0.7813\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 22s 373us/sample - loss: 2.4320 - recon_error: 0.7645 - val_loss: 1.6707 - val_recon_error: 0.5895\n",
      "Model training Complete\n",
      "Model saved to: dataset_1_weights_test_ndim_2_filters_64.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=64 : dim_representation=10 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 26s 428us/sample - loss: 2.2147 - recon_error: 0.5536 - val_loss: 1.6081 - val_recon_error: 0.5555\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 23s 377us/sample - loss: 1.2661 - recon_error: 0.5240 - val_loss: 1.0714 - val_recon_error: 0.5174\n",
      "Model training Complete\n",
      "Model saved to: dataset_1_weights_test_ndim_10_filters_64.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=64 : dim_representation=20 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 26s 437us/sample - loss: 2.4523 - recon_error: 0.6007 - val_loss: 1.7019 - val_recon_error: 0.5490\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 23s 382us/sample - loss: 1.2609 - recon_error: 0.4668 - val_loss: 1.0157 - val_recon_error: 0.4146\n",
      "Model training Complete\n",
      "Model saved to: dataset_1_weights_test_ndim_20_filters_64.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=64 : dim_representation=100 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 30s 493us/sample - loss: 1.9269 - recon_error: 0.4614 - val_loss: 1.0615 - val_recon_error: 0.3724\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 26s 436us/sample - loss: 0.8335 - recon_error: 0.3439 - val_loss: 0.6627 - val_recon_error: 0.3160\n",
      "Model training Complete\n",
      "Model saved to: dataset_1_weights_test_ndim_100_filters_64.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=128 : dim_representation=2 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 50s 837us/sample - loss: 2.4599 - recon_error: 0.7643 - val_loss: 1.5722 - val_recon_error: 0.7821\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 46s 773us/sample - loss: 1.2742 - recon_error: 0.7861 - val_loss: 1.0812 - val_recon_error: 0.7946\n",
      "Model training Complete\n",
      "Model saved to: dataset_1_weights_test_ndim_2_filters_128.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=128 : dim_representation=10 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 51s 853us/sample - loss: 1.9934 - recon_error: 0.5132 - val_loss: 1.0274 - val_recon_error: 0.4866\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 47s 783us/sample - loss: 0.8526 - recon_error: 0.4814 - val_loss: 0.7245 - val_recon_error: 0.4732\n",
      "Model training Complete\n",
      "Model saved to: dataset_1_weights_test_ndim_10_filters_128.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=128 : dim_representation=20 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 52s 865us/sample - loss: 2.1279 - recon_error: 0.7341 - val_loss: 1.2338 - val_recon_error: 0.6450\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 48s 798us/sample - loss: 0.8838 - recon_error: 0.5264 - val_loss: 0.7024 - val_recon_error: 0.4380\n",
      "Model training Complete\n",
      "Model saved to: dataset_1_weights_test_ndim_20_filters_128.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=128 : dim_representation=100 ###\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 59s 983us/sample - loss: 2.3460 - recon_error: 0.6952 - val_loss: 0.9195 - val_recon_error: 0.4578\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 54s 906us/sample - loss: 0.7054 - recon_error: 0.3824 - val_loss: 0.5310 - val_recon_error: 0.3196\n",
      "Model training Complete\n",
      "Model saved to: dataset_1_weights_test_ndim_100_filters_128.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=32 : dim_representation=2 ###\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/2\n",
      "73257/73257 [==============================] - 34s 467us/sample - loss: 0.6890 - recon_error: 0.1954 - val_loss: 0.6356 - val_recon_error: 0.2202\n",
      "Epoch 2/2\n",
      "73257/73257 [==============================] - 29s 398us/sample - loss: 0.6174 - recon_error: 0.2436 - val_loss: 0.5886 - val_recon_error: 0.2599\n",
      "Model training Complete\n",
      "Model saved to: dataset_2_weights_test_ndim_2_filters_32.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=32 : dim_representation=10 ###\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/2\n",
      "73257/73257 [==============================] - 34s 470us/sample - loss: 0.7269 - recon_error: 0.2403 - val_loss: 0.6637 - val_recon_error: 0.2028\n",
      "Epoch 2/2\n",
      "73257/73257 [==============================] - 30s 408us/sample - loss: 0.6439 - recon_error: 0.2193 - val_loss: 0.6131 - val_recon_error: 0.2128\n",
      "Model training Complete\n",
      "Model saved to: dataset_2_weights_test_ndim_10_filters_32.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=32 : dim_representation=20 ###\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/2\n",
      "73257/73257 [==============================] - 35s 478us/sample - loss: 0.6951 - recon_error: 0.1807 - val_loss: 0.6378 - val_recon_error: 0.2024\n",
      "Epoch 2/2\n",
      "73257/73257 [==============================] - 30s 416us/sample - loss: 0.6149 - recon_error: 0.2240 - val_loss: 0.5826 - val_recon_error: 0.2364\n",
      "Model training Complete\n",
      "Model saved to: dataset_2_weights_test_ndim_20_filters_32.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=32 : dim_representation=100 ###\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/2\n",
      "73257/73257 [==============================] - 38s 523us/sample - loss: 0.6938 - recon_error: 0.1981 - val_loss: 0.6240 - val_recon_error: 0.1903\n",
      "Epoch 2/2\n",
      "73257/73257 [==============================] - 33s 450us/sample - loss: 0.6032 - recon_error: 0.2033 - val_loss: 0.5678 - val_recon_error: 0.1894\n",
      "Model training Complete\n",
      "Model saved to: dataset_2_weights_test_ndim_100_filters_32.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=64 : dim_representation=2 ###\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/2\n",
      "73257/73257 [==============================] - 50s 679us/sample - loss: 0.6363 - recon_error: 0.2281 - val_loss: 0.5702 - val_recon_error: 0.2667\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73257/73257 [==============================] - 44s 602us/sample - loss: 0.5636 - recon_error: 0.3179 - val_loss: 0.5339 - val_recon_error: 0.3122\n",
      "Model training Complete\n",
      "Model saved to: dataset_2_weights_test_ndim_2_filters_64.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=64 : dim_representation=10 ###\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/2\n",
      "73257/73257 [==============================] - 50s 685us/sample - loss: 0.6441 - recon_error: 0.2639 - val_loss: 0.5610 - val_recon_error: 0.2924\n",
      "Epoch 2/2\n",
      "73257/73257 [==============================] - 44s 599us/sample - loss: 0.5529 - recon_error: 0.3557 - val_loss: 0.5191 - val_recon_error: 0.3435\n",
      "Model training Complete\n",
      "Model saved to: dataset_2_weights_test_ndim_10_filters_64.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=64 : dim_representation=20 ###\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/2\n",
      "73257/73257 [==============================] - 51s 695us/sample - loss: 0.6375 - recon_error: 0.2154 - val_loss: 0.5658 - val_recon_error: 0.2426\n",
      "Epoch 2/2\n",
      "73257/73257 [==============================] - 45s 619us/sample - loss: 0.5592 - recon_error: 0.2979 - val_loss: 0.5236 - val_recon_error: 0.2941\n",
      "Model training Complete\n",
      "Model saved to: dataset_2_weights_test_ndim_20_filters_64.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=64 : dim_representation=100 ###\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/2\n",
      "73257/73257 [==============================] - 56s 760us/sample - loss: 0.6215 - recon_error: 0.2508 - val_loss: 0.5465 - val_recon_error: 0.2822\n",
      "Epoch 2/2\n",
      "73257/73257 [==============================] - 49s 674us/sample - loss: 0.5397 - recon_error: 0.3067 - val_loss: 0.4928 - val_recon_error: 0.2758\n",
      "Model training Complete\n",
      "Model saved to: dataset_2_weights_test_ndim_100_filters_64.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=128 : dim_representation=2 ###\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/2\n",
      "73257/73257 [==============================] - 90s 1ms/sample - loss: 0.5856 - recon_error: 0.3211 - val_loss: 0.5156 - val_recon_error: 0.3732\n",
      "Epoch 2/2\n",
      "73257/73257 [==============================] - 83s 1ms/sample - loss: 0.5267 - recon_error: 0.4527 - val_loss: 0.4951 - val_recon_error: 0.4287\n",
      "Model training Complete\n",
      "Model saved to: dataset_2_weights_test_ndim_2_filters_128.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=128 : dim_representation=10 ###\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/2\n",
      "73257/73257 [==============================] - 90s 1ms/sample - loss: 0.5695 - recon_error: 0.3753 - val_loss: 0.5023 - val_recon_error: 0.4018\n",
      "Epoch 2/2\n",
      "73257/73257 [==============================] - 83s 1ms/sample - loss: 0.5157 - recon_error: 0.4831 - val_loss: 0.4861 - val_recon_error: 0.4453\n",
      "Model training Complete\n",
      "Model saved to: dataset_2_weights_test_ndim_10_filters_128.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=128 : dim_representation=20 ###\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/2\n",
      "73257/73257 [==============================] - 91s 1ms/sample - loss: 0.5736 - recon_error: 0.3349 - val_loss: 0.5111 - val_recon_error: 0.3648\n",
      "Epoch 2/2\n",
      "73257/73257 [==============================] - 85s 1ms/sample - loss: 0.5183 - recon_error: 0.4423 - val_loss: 0.4851 - val_recon_error: 0.4075\n",
      "Model training Complete\n",
      "Model saved to: dataset_2_weights_test_ndim_20_filters_128.h5 . Use these weights for image reconstruction purposes.\n",
      "### CNN-VAE INITIALIZED ###\n",
      "### filters=128 : dim_representation=100 ###\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/2\n",
      "73257/73257 [==============================] - 101s 1ms/sample - loss: 0.5677 - recon_error: 0.3575 - val_loss: 0.4910 - val_recon_error: 0.3518\n",
      "Epoch 2/2\n",
      "73257/73257 [==============================] - 94s 1ms/sample - loss: 0.4907 - recon_error: 0.3743 - val_loss: 0.4417 - val_recon_error: 0.3241\n",
      "Model training Complete\n",
      "Model saved to: dataset_2_weights_test_ndim_100_filters_128.h5 . Use these weights for image reconstruction purposes.\n"
     ]
    }
   ],
   "source": [
    "#Model training block\n",
    "import numpy as np\n",
    "import os\n",
    "from train_CNN_VAE_create_folders import train_model\n",
    "\n",
    "\n",
    "dataset_prep = np.asarray([prepare_dataset_mnist, prepare_dataset_fashion_mnist, prepare_dataset_mat])\n",
    "model_hyperparameters = [[2,32],[10,32],[20,32],[100,32],\n",
    "                         [2,64],[10,64],[20,64],[100,64],\n",
    "                         [2,128],[10,128],[20,128],[100,128]]\n",
    "\n",
    "def train_all_datasets(add_list_of_datasets):\n",
    "    #create names for weights_test\n",
    "    weight_names_list = []\n",
    "    for i in range(len(dataset_prep)):\n",
    "        filename = 'dataset_'+str(i)+'_run_initial'\n",
    "        weight_names_list.append(filename)\n",
    "    weight_names_list = np.array(weight_names_list)\n",
    "    \n",
    "    return_here_path = os.getcwd()\n",
    "    for i in range(len(dataset_prep)):\n",
    "        os.chdir(return_here_path)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = dataset_prep[i]() #cycle through each function to create dataset\n",
    "        weights_name_dataset = weight_names_list[i] #create basename for folder to be created for a particular dataset\n",
    "        \n",
    "        #automate folder creation for each dataset\n",
    "        path_dataset = os.path.abspath(os.getcwd())+'\\\\'+str(weights_name_dataset)\n",
    "        if not os.path.exists(path_dataset):\n",
    "            os.makedirs(path_dataset)\n",
    "        \n",
    "        for j in model_hyperparameters:\n",
    "            os.chdir(path_dataset) \n",
    "            weights_name = weights_name_dataset+'_ndim_'+str(j[0])+'_filters_'+str(j[1])\n",
    "            train_model(X_train, X_test, epochs = 2, dim_representation = j[0], b_f = j[1], save_weight_name = weights_name) #(train_set, test_set, modelname, desired epochs, filename to save to)\n",
    "            \n",
    "    os.chdir(return_here_path) #return to working directory of this script\n",
    "    return\n",
    "\n",
    "train_all_datasets(dataset_prep)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\31687\\Desktop\\VAE-SVHN-master\\Automated\\VAE_reconstruct.py:70: The name tf.keras.initializers.he_normal is deprecated. Please use tf.compat.v1.keras.initializers.he_normal instead.\n",
      "\n",
      "10000/10000 [==============================] - 1s 86us/sample\n",
      "[1.0554974  1.0804578  1.0220969  0.78670686 1.0424025  1.0620867\n",
      " 1.0622861  1.0786114  1.1480128  1.1251296  1.1014254  0.88116807\n",
      " 1.0718195  0.80007833 1.1106603  0.9825944  1.0598474  1.0570191\n",
      " 0.7640308  1.0317177  1.139292   1.0602434  0.9386667  1.0526534\n",
      " 0.99005795 0.68407387 1.033162   1.0826833  0.7808364  1.055481\n",
      " 1.1156068  1.0401491  1.1090081  1.0209597  1.1348169  1.0278729\n",
      " 1.0852482  1.0707949  1.0337675  1.1008234  1.0133352  1.0407069\n",
      " 1.1023077  1.0199211  1.0782876  1.0240452  1.0942373  1.0108815\n",
      " 1.2574371  1.0901507  1.0629658  1.189437   1.0525415  0.95290446\n",
      " 0.7669978  1.109618   1.0365901  1.0377191  1.0900735  1.0053749\n",
      " 1.1460402  1.1075429  1.0029141  1.0503497  1.1158332  1.0194175\n",
      " 1.0062621  1.0096481  1.154299   0.8655947  1.0831269  0.8148277\n",
      " 1.0455501  1.0768989  1.070328   1.0830618  1.0478481  1.029881\n",
      " 1.07757    1.2429026  1.1062794  1.0123395  1.0224035  1.0657027\n",
      " 1.0426519  1.0215794  1.1312732  1.1022613  0.96793324 1.0823904\n",
      " 1.0902615  1.0377862  0.99481916 1.2032602  1.1534675  0.93130016\n",
      " 1.0412099  1.1510568  1.0727234  1.0409999 ]\n",
      "Reconstruction errors saved in file: dataset_0_weights_test_ndim_2_filters_32_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_0_weights_test_ndim_2_filters_32_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[2, 32]\n",
      "10000/10000 [==============================] - 1s 98us/sample\n",
      "[1.1569176  1.5240513  0.9974421  1.5184582  1.1335783  1.048691\n",
      " 1.1886173  1.2069119  1.3923448  1.2404704  1.4954318  1.3557678\n",
      " 1.0769678  1.380715   1.1231096  1.3048668  1.1566787  1.3233452\n",
      " 1.6625443  1.0186095  1.2130208  1.2223238  1.2099382  1.1520402\n",
      " 0.9842004  1.989357   1.141577   1.162178   1.504753   1.0768982\n",
      " 1.3102357  1.000144   1.3902158  1.4069765  1.1876012  1.4033546\n",
      " 1.1797713  1.073296   1.1943307  1.1516125  0.98916286 1.03282\n",
      " 1.1655345  1.1882656  1.183126   1.1268193  1.1581177  1.0389135\n",
      " 1.516275   1.2832558  1.1441917  1.6205208  1.2036797  1.194595\n",
      " 1.5927119  1.3075881  1.4036158  1.0388561  1.2007607  1.0759948\n",
      " 1.5395585  1.3126843  0.9300417  1.1038461  1.3681241  0.9705227\n",
      " 1.2122109  1.2181386  1.4887013  1.5436327  1.3535463  1.8395976\n",
      " 1.4608135  1.23579    1.0573784  1.1655922  1.1679122  1.1151637\n",
      " 1.0802505  1.4942707  1.2284583  1.2182283  1.4384698  1.1450326\n",
      " 1.2738563  1.4815749  1.1601305  1.4145578  1.3469651  1.086992\n",
      " 1.2879969  1.136891   0.9379484  1.4850934  1.2197483  1.46392\n",
      " 1.0135921  1.3716667  1.2158778  1.3396844 ]\n",
      "Reconstruction errors saved in file: dataset_0_weights_test_ndim_10_filters_32_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_0_weights_test_ndim_10_filters_32_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[10, 32]\n",
      "10000/10000 [==============================] - ETA:  - 1s 102us/sample\n",
      "[1.060572   1.0874014  1.026388   0.82419825 1.0397731  1.0686889\n",
      " 1.0689147  1.088197   1.0469812  1.1602912  0.85764825 0.97096425\n",
      " 1.0774902  0.9631195  1.1090425  1.0225204  1.0947634  1.1084377\n",
      " 0.8238039  1.0404935  1.120278   1.0073628  1.0612831  1.0399663\n",
      " 0.99142444 0.6713414  1.039326   1.0964891  0.7793622  1.0614896\n",
      " 1.1000158  1.0439354  1.0964688  0.9809956  1.1431441  0.82860124\n",
      " 1.0822115  1.0770447  1.0266438  1.1094095  1.0162308  1.0436667\n",
      " 1.0917199  1.0369895  1.0822414  0.9897913  1.1141179  1.0148382\n",
      " 1.2389053  1.0776043  1.0764954  0.812621   1.0714153  1.0060298\n",
      " 1.0070294  1.021971   1.1314038  1.0427012  1.098661   1.0053319\n",
      " 1.1313133  0.8888442  1.0075718  1.0420214  1.1282132  1.0241909\n",
      " 0.95077145 1.0261327  1.1063209  0.86443675 1.1172054  0.7360997\n",
      " 0.95839506 1.1350731  1.0768297  1.0862716  1.0434983  1.0396059\n",
      " 1.0955161  1.21542    1.1141073  1.1220559  1.0705589  1.0723859\n",
      " 1.0667504  1.2200898  1.148782   0.8960944  1.0513419  1.0849732\n",
      " 0.97667414 1.0584222  1.0072879  1.2439878  1.1641593  1.1344866\n",
      " 1.0469439  1.1755992  1.059916   1.1767006 ]\n",
      "Reconstruction errors saved in file: dataset_0_weights_test_ndim_20_filters_32_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_0_weights_test_ndim_20_filters_32_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[20, 32]\n",
      "10000/10000 [==============================] - 1s 112us/sample\n",
      "[0.76274335 0.72298235 0.80951583 0.5035834  0.7268883  0.7403207\n",
      " 0.7238037  0.67264426 0.6418432  0.5581496  0.75768495 0.6781565\n",
      " 0.59606004 0.6484298  0.70665324 0.81682664 0.6593356  0.74547046\n",
      " 0.7078794  0.70245844 0.5400347  0.6707611  0.70207244 0.68351394\n",
      " 0.76889294 0.5578764  0.80717546 0.6403848  0.5510053  0.7702188\n",
      " 0.64211565 0.8019544  0.6975854  0.8327662  0.6567956  0.7857115\n",
      " 0.74572384 0.74692106 0.75160253 0.6529588  0.8598508  0.7235521\n",
      " 0.61846894 0.7995652  0.69657016 0.66847116 0.6995213  0.76588905\n",
      " 0.48918116 0.7198266  0.6700923  0.60272616 0.6192521  0.84695995\n",
      " 0.77695525 0.60080343 0.67813724 0.80062836 0.60094965 0.7835502\n",
      " 0.80228907 0.5641228  0.74381363 0.6751604  0.6521728  0.7158654\n",
      " 0.6902575  0.7191613  0.46607265 0.81086916 0.75174856 0.6936439\n",
      " 0.78413826 0.5568133  0.70999867 0.64657557 0.7305983  0.76122135\n",
      " 0.647898   0.5311492  0.69375813 0.6124532  0.6741199  0.74771374\n",
      " 0.58966655 0.55511624 0.595241   0.6748512  0.71613073 0.69655514\n",
      " 0.66165835 0.6540317  0.7155799  0.48159945 0.62845063 0.41512626\n",
      " 0.7890519  0.5892466  0.70253277 0.5861598 ]\n",
      "Reconstruction errors saved in file: dataset_0_weights_test_ndim_100_filters_32_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_0_weights_test_ndim_100_filters_32_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[100, 32]\n",
      "10000/10000 [==============================] - 2s 165us/sample\n",
      "[3.7957084  3.2360654  3.3699415  0.74422467 5.5591407  4.5612807\n",
      " 6.309188   6.5196695  3.8259063  3.0564725  0.80316335 0.7868253\n",
      " 5.317127   0.7656661  5.351866   0.9966421  6.9846783  2.9672801\n",
      " 0.70334494 3.329709   8.525903   6.685035   0.98847085 4.8303785\n",
      " 3.2281168  0.68975544 2.2211897  6.8213673  0.7267478  4.3850417\n",
      " 7.0987577  3.758123   3.2859101  0.8307197  5.5014033  0.76234263\n",
      " 5.4336123  4.7579727  2.4736543  6.1049604  2.613175   5.033193\n",
      " 7.0813446  2.3221998  5.942792   5.126162   5.50468    3.8356848\n",
      " 4.2937045  3.1463165  6.110436   0.69978845 5.803137   2.063107\n",
      " 0.76394546 3.5258944  1.4845095  3.6222863  3.890656   1.9195055\n",
      " 3.4292898  0.75430405 3.459818   2.8789158  3.5852642  3.7097104\n",
      " 0.9520549  3.032161   4.370054   0.8055684  2.7067244  0.7453629\n",
      " 0.93077177 8.738741   5.050806   5.3025727  4.88323    3.4186628\n",
      " 6.3131146  3.421835   5.508557   4.6925755  2.7416627  5.106533\n",
      " 8.156064   1.7628407  7.198011   1.041358   0.77690536 5.497877\n",
      " 4.4137254  6.471204   3.4292114  4.2799916  7.6955123  0.6820355\n",
      " 4.0224075  3.7712815  3.0016358  4.0757747 ]\n",
      "Reconstruction errors saved in file: dataset_0_weights_test_ndim_2_filters_64_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_0_weights_test_ndim_2_filters_64_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[2, 64]\n",
      "10000/10000 [==============================] - 2s 163us/sample\n",
      "[1.5860584  0.80442894 1.2974224  0.76861984 1.332367   1.4969437\n",
      " 1.6762207  1.6820645  1.6010321  1.7026374  0.80078626 1.7430378\n",
      " 1.5166789  2.0295408  1.6637726  1.1120454  1.4795567  1.8140478\n",
      " 1.719556   1.4694768  1.8368441  1.2619606  1.469863   1.6534368\n",
      " 1.2937918  0.6609652  1.4586852  1.4191593  0.7870444  1.4540251\n",
      " 1.612304   1.3613293  1.9415084  1.6609697  1.6441199  0.7783399\n",
      " 1.4058822  1.5140197  1.2613212  1.7039561  1.1991003  1.5117563\n",
      " 1.8604254  1.4367104  1.5674081  1.1018251  1.6262454  1.370542\n",
      " 2.5898733  1.8390739  1.2972875  2.0699263  1.5726585  0.8972488\n",
      " 0.7563489  1.5899909  1.9620633  1.346016   1.6636177  1.3114873\n",
      " 2.013884   0.7915225  1.3465928  1.7380742  1.8777925  1.3806173\n",
      " 1.3122482  1.6340758  0.7774274  1.5655948  1.8240948  0.79998046\n",
      " 0.9502591  1.7228434  1.5450706  1.7968459  1.3433379  1.4074165\n",
      " 1.7169178  2.4925685  1.6974747  1.6910366  0.85487765 1.5813411\n",
      " 1.7828922  1.7764598  1.9674954  1.5903512  1.5203677  1.6115516\n",
      " 0.87517965 1.4140754  1.3610669  1.5443245  1.9333314  2.5898066\n",
      " 1.3897308  2.1593382  1.0292476  2.1536477 ]\n",
      "Reconstruction errors saved in file: dataset_0_weights_test_ndim_10_filters_64_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_0_weights_test_ndim_10_filters_64_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[10, 64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 183us/sample\n",
      "[0.7887924  0.85486156 0.8311704  0.6433495  0.87146693 0.756458\n",
      " 0.7779601  0.7337509  0.8021408  0.626949   1.0371382  0.8025463\n",
      " 0.53981084 0.87147576 0.7098337  1.0298465  0.7160202  0.81556565\n",
      " 0.94849944 0.67990035 0.5460549  0.7421254  0.8691601  0.6673502\n",
      " 0.74816275 0.8635676  0.86961806 0.6843297  0.70040965 0.7441271\n",
      " 0.6485055  0.77967757 0.78870595 1.0786076  0.6858028  0.99878824\n",
      " 0.7350685  0.7301662  0.79029685 0.6531041  0.8650247  0.66045684\n",
      " 0.6034012  0.8918085  0.6652979  0.72508955 0.71185976 0.7848288\n",
      " 0.5747906  0.90628034 0.6792167  0.7138327  0.6699227  0.9947085\n",
      " 1.006388   0.7184946  0.8902958  0.8290428  0.659554   0.8853943\n",
      " 1.0661066  0.67233646 0.6600977  0.6288806  0.722027   0.6692013\n",
      " 0.78435564 0.8597189  0.44108906 0.976404   0.8588118  1.0456529\n",
      " 1.0114284  0.59831405 0.7139268  0.6423075  0.7723498  0.7701104\n",
      " 0.6250612  0.657804   0.7211719  0.6747749  0.84364605 0.7532213\n",
      " 0.6954626  0.7042674  0.60295844 0.7932558  0.8693438  0.6983356\n",
      " 0.7833216  0.74254495 0.6945136  0.47057354 0.6610453  0.56338716\n",
      " 0.78456765 0.6120306  0.8363131  0.67265683]\n",
      "Reconstruction errors saved in file: dataset_0_weights_test_ndim_20_filters_64_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_0_weights_test_ndim_20_filters_64_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[20, 64]\n",
      "10000/10000 [==============================] - 2s 206us/sample\n",
      "[0.7552514  1.1489208  0.7632809  0.7992734  0.9222557  0.7036716\n",
      " 0.8292822  0.80445075 0.89933527 0.64165473 1.2314589  0.98259187\n",
      " 0.5458822  1.103696   0.6571617  1.1276559  0.7659123  0.82755613\n",
      " 1.0857549  0.74521387 0.55640143 0.81023264 0.92409813 0.72047126\n",
      " 0.8095733  1.1018682  0.8905424  0.75611424 0.88413334 0.7324081\n",
      " 0.66779006 0.7574417  0.9875565  1.1849647  0.6541839  1.1169747\n",
      " 0.71171504 0.6986195  0.8865133  0.65355295 0.83562684 0.62496096\n",
      " 0.63281405 0.9844348  0.6456198  0.792495   0.70631796 0.83185315\n",
      " 0.7082581  0.9866355  0.78352666 0.92540294 0.7679573  1.0529866\n",
      " 1.144859   0.9126842  1.0731641  0.7731435  0.742207   0.9236052\n",
      " 1.1711754  0.7671263  0.75863713 0.6653674  0.79635346 0.6912127\n",
      " 0.86938155 0.86127675 0.5785516  1.1063906  0.90092367 1.299374\n",
      " 1.1207625  0.5729092  0.66124713 0.6633988  0.9228327  0.77892077\n",
      " 0.62426656 0.74585456 0.8302381  0.7294871  0.9030462  0.78570044\n",
      " 0.83058536 0.90545356 0.53877294 0.8582484  0.9785684  0.65977556\n",
      " 0.8548167  0.70091254 0.7446875  0.51958907 0.6213961  0.60794604\n",
      " 0.73639846 0.613761   0.9439081  0.7628683 ]\n",
      "Reconstruction errors saved in file: dataset_0_weights_test_ndim_100_filters_64_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_0_weights_test_ndim_100_filters_64_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[100, 64]\n",
      "10000/10000 [==============================] - 3s 306us/sample\n",
      "[ 2.2276013   1.3937895   2.7612498   4.476875    4.7627187   5.6935496\n",
      "  5.5215187   1.6122533   3.9919531   3.3816962   0.72098047  1.445816\n",
      "  1.4954674  14.529739    4.291055    3.1735876   5.278184    9.772439\n",
      "  9.767356    1.4312353   4.315087    2.220802    9.46567     4.239536\n",
      "  5.1148653   0.6670069   4.5924554   3.2862089  16.547775    1.9333355\n",
      "  1.6105578   2.912296    2.2293618   0.80327326  4.940094    2.3964405\n",
      "  2.9402902   2.847955    1.5635983   4.3011384   2.18632     2.970573\n",
      "  1.6325898   4.5508842   3.5318913   3.2291358   3.207409    5.7226825\n",
      "  0.6284155  12.184243    4.6827607   1.7881186   3.2369432   3.7796223\n",
      "  0.72401005  5.851915    8.350689    3.9463603  11.662766    5.4323463\n",
      "  3.5459335   0.6080728   2.4865816   2.9657848   7.879334    3.0609138\n",
      "  8.32913     8.504085    1.1304313   0.8055572  10.151944    0.72436297\n",
      "  6.0508204   5.279189    4.027537    6.826693    3.4529467   3.979744\n",
      "  4.834101   16.96286     1.8260093   3.1809354   6.558613    5.281235\n",
      "  1.727553    0.9131408   3.9027715   1.042815    2.638961    4.1669946\n",
      "  6.197816    4.4063206   2.080859    0.6844848   2.1697009  20.24231\n",
      "  3.5475502   0.5936977   1.4630673   4.6541333 ]\n",
      "Reconstruction errors saved in file: dataset_0_weights_test_ndim_2_filters_128_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_0_weights_test_ndim_2_filters_128_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[2, 128]\n",
      "10000/10000 [==============================] - 3s 308us/sample\n",
      "[11.591608   26.734642    9.939819    0.75980616 11.771167   14.675108\n",
      " 19.681269   13.731484   30.691496    2.0980434   0.80006605  0.7995644\n",
      " 16.184885    0.80182916 18.164051   12.040842   21.814825   22.347252\n",
      " 12.5246105   9.881363   26.04511     3.4359522   0.80808014 12.680808\n",
      "  7.3570843   0.67029214  9.07075    14.183335    0.72531724 12.951263\n",
      " 16.462126   10.794634   17.104506    0.8306578  26.3249      2.0128856\n",
      " 14.298325   14.906726   13.039927   19.927935    7.099603   11.466639\n",
      " 21.406622    9.819699   11.519778    7.857727   13.623601    8.674949\n",
      " 26.012821   22.09816    10.807176    0.70321923 16.038761    9.452435\n",
      "  0.76265496 26.55962    17.710247   10.567782   19.735153    9.560187\n",
      " 17.93769     0.7278226  10.487177   15.662456   20.256617    8.38863\n",
      "  0.7942927   7.0335884  23.91787     0.80305576 16.291624    0.7343815\n",
      " 16.4821     31.708704   15.856683   10.460646    5.955437   14.41212\n",
      " 19.690046   25.557812   21.42171    19.04325    28.859833   13.78375\n",
      " 27.022999   37.30679    26.910732   25.28737     0.75266933 17.28396\n",
      " 14.232088    6.2195992   8.4150505  35.816975   25.535028    0.63960016\n",
      "  8.260484   19.707335   13.9786415  28.919527  ]\n",
      "Reconstruction errors saved in file: dataset_0_weights_test_ndim_10_filters_128_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_0_weights_test_ndim_10_filters_128_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[10, 128]\n",
      "10000/10000 [==============================] - 3s 328us/sample\n",
      "[0.6969607  0.92996615 0.73266256 0.65492195 0.9087054  0.6451812\n",
      " 0.72137475 0.6787297  0.83779365 0.6016092  1.0690966  0.82677364\n",
      " 0.55112725 0.93104404 0.59498674 0.9427899  0.73880726 0.7323747\n",
      " 0.8707988  0.71797574 0.4350435  0.7172285  0.8252247  0.67442054\n",
      " 0.8105905  0.8817276  0.8404836  0.71777207 0.7264879  0.65537393\n",
      " 0.5248679  0.71013516 0.71980524 1.0881162  0.6980278  1.0208353\n",
      " 0.6703024  0.62277216 0.804862   0.5191647  0.7949578  0.62040234\n",
      " 0.6289497  0.92396426 0.633777   0.6866006  0.6243876  0.80650705\n",
      " 0.57486    0.9811297  0.70956933 0.6737705  0.7161079  0.9584803\n",
      " 1.0737631  0.7009459  0.923752   0.71517646 0.70301145 0.8276877\n",
      " 0.9387716  0.7019116  0.6874177  0.65584993 0.7301059  0.60542375\n",
      " 0.8386104  0.9056657  0.36864072 1.0209441  0.7803587  1.0519397\n",
      " 1.0627421  0.55763423 0.57263315 0.6255731  0.7178635  0.74467784\n",
      " 0.5061778  0.63676274 0.66912544 0.66029674 0.8762625  0.71865153\n",
      " 0.73006797 0.7198457  0.4400082  0.706618   0.8427839  0.6183113\n",
      " 0.69240284 0.70073646 0.7177458  0.33406913 0.49362078 0.5875236\n",
      " 0.6925555  0.451247   0.86337936 0.68337715]\n",
      "Reconstruction errors saved in file: dataset_0_weights_test_ndim_20_filters_128_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_0_weights_test_ndim_20_filters_128_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[20, 128]\n",
      "10000/10000 [==============================] - 3s 347us/sample\n",
      "[0.8398934  1.1986142  0.76151526 0.9297846  1.0443937  0.7062744\n",
      " 0.9582897  0.93898016 0.98105866 0.75846905 1.3987148  1.1785871\n",
      " 0.5877892  1.1981457  0.68618524 1.288374   0.85833937 0.95221263\n",
      " 1.2955483  0.7505701  0.61490875 0.91791165 1.0591308  0.7972079\n",
      " 0.8349938  1.3928815  0.94778544 0.8235824  0.97468966 0.9036144\n",
      " 0.8477946  0.8722754  1.1271797  1.3985779  0.74140537 1.245984\n",
      " 0.8283218  0.83258337 0.9404028  0.6819678  0.8476036  0.7216784\n",
      " 0.7149926  1.0004301  0.8247101  0.9480975  0.9489747  0.8321193\n",
      " 0.90921164 1.0712652  0.81375885 1.1142553  0.82805663 1.2204645\n",
      " 1.3822832  1.0471942  1.1720941  0.7618001  0.8022871  0.8844961\n",
      " 1.3243294  0.8389158  0.7516667  0.6253724  0.873981   0.72638226\n",
      " 1.0109663  0.919474   0.68399006 1.2476592  1.001969   1.4968208\n",
      " 1.2701389  0.7178023  0.7496207  0.74594915 0.9752944  0.8081439\n",
      " 0.6492473  0.8620507  0.84981555 0.7838632  1.0403283  0.85772604\n",
      " 0.95661753 1.0362855  0.6475682  1.0748625  1.0797803  0.7079576\n",
      " 0.9998865  0.8073454  0.7039791  0.7244448  0.8258887  0.81980413\n",
      " 0.92079216 0.78903997 1.0856128  0.86834687]\n",
      "Reconstruction errors saved in file: dataset_0_weights_test_ndim_100_filters_128_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_0_weights_test_ndim_100_filters_128_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[100, 128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 282us/sample\n",
      "[2.329051   0.30506095 1.8845949  2.0423605  0.3717399  1.5249307\n",
      " 0.709499   0.46922934 2.0423036  3.4665713  0.34671384 2.9381838\n",
      " 3.5526197  2.0190282  0.27885577 1.3896344  0.45377505 0.387302\n",
      " 0.46530074 0.35157815 0.17437354 4.4702926  4.39905    4.591711\n",
      " 1.9176729  0.5683929  0.2817369  0.5831195  1.6202466  0.49193257\n",
      " 0.37895712 2.4391441  2.2789168  0.52085096 1.0307245  0.5453502\n",
      " 6.0241175  1.9101808  3.137378   1.2545906  0.35063568 2.2717323\n",
      " 0.41738102 1.9808787  0.27235484 1.1464065  0.23288327 1.9152328\n",
      " 0.47408468 0.2781472  0.22491845 0.5273021  2.3526852  0.16857482\n",
      " 0.4075235  0.22156037 0.38285094 0.3613754  0.65812933 0.56874\n",
      " 4.035768   3.5569923  0.5191565  2.6063657  1.2910608  1.6802567\n",
      " 0.4905034  1.0017326  1.0824243  0.3591299  4.121629   0.610546\n",
      " 0.1553481  0.3635015  0.33405602 0.85211754 1.921241   0.26227278\n",
      " 0.39847976 0.24813451 0.98098356 0.30508918 2.6523392  0.6109095\n",
      " 3.687159   0.3685032  1.487401   0.3040984  0.3769851  0.19583403\n",
      " 3.1388865  1.0215838  0.28726757 5.4582224  2.1194055  0.49834758\n",
      " 0.53074586 1.3287998  0.21342596 0.2951054 ]\n",
      "Reconstruction errors saved in file: dataset_1_weights_test_ndim_2_filters_32_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_1_weights_test_ndim_2_filters_32_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[2, 32]\n",
      "10000/10000 [==============================] - 3s 287us/sample\n",
      "[2.5970142  0.31391218 7.9686537  4.2483306  0.3657306  2.3630748\n",
      " 0.69606614 0.4632976  1.5299033  2.8522356  0.35880998 2.5455866\n",
      " 2.854045   5.542464   0.26212138 3.4530873  0.45077902 0.362434\n",
      " 0.45478165 0.35704952 0.17396715 4.079659   6.5517883  5.222294\n",
      " 3.925231   0.55158406 0.28441238 0.5835035  0.8069167  0.43343228\n",
      " 0.35043806 1.0478338  3.2221446  0.47711268 0.60753703 0.5313609\n",
      " 4.024551   1.4537683  4.759506   0.6660632  0.346498   8.108393\n",
      " 0.451677   2.2981646  0.26088616 0.8156402  0.20274621 5.3757396\n",
      " 0.4781672  0.27026254 0.2223393  0.52219033 1.7261398  0.16544499\n",
      " 0.4172149  0.22359717 0.36169302 0.35430813 0.5682803  0.5848898\n",
      " 3.7862008  4.2669044  0.48271617 1.9043972  8.081811   2.3720357\n",
      " 0.5214784  1.5170609  2.3008416  0.33606395 2.5927649  0.5871932\n",
      " 0.16555224 0.35986117 0.3271756  1.0291108  5.452362   0.27171004\n",
      " 0.3860177  0.24328366 1.3304223  0.27387118 1.9702871  0.5419673\n",
      " 2.9253974  0.38362265 1.4684756  0.28696212 0.3956218  0.18486373\n",
      " 1.7314825  1.0392421  0.2801464  5.417656   5.88866    0.41703743\n",
      " 0.5349348  3.771983   0.19855121 0.29512298]\n",
      "Reconstruction errors saved in file: dataset_1_weights_test_ndim_10_filters_32_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_1_weights_test_ndim_10_filters_32_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[10, 32]\n",
      "10000/10000 [==============================] - 3s 306us/sample\n",
      "[0.7543213  0.37110135 0.9738365  0.822193   0.41045716 0.83927417\n",
      " 0.73239154 0.5183133  0.91217065 0.8046353  0.5562947  0.81022626\n",
      " 0.7697699  0.8928894  0.3291129  0.7634782  0.38757536 0.51865274\n",
      " 0.67783624 0.7335978  0.39972317 0.7968709  0.8798999  0.87288654\n",
      " 0.79042655 0.55413544 0.6306631  1.0229903  0.7006144  0.7670434\n",
      " 0.56626827 0.85804284 0.90412617 0.839245   0.74192053 0.53775764\n",
      " 0.88659036 0.8837355  0.8861976  0.77494067 0.78213626 1.0125216\n",
      " 0.7538644  0.8805602  0.35065928 0.720859   0.40980607 0.8585069\n",
      " 0.54835975 0.5043176  0.27741405 0.5245583  0.89062303 0.25135073\n",
      " 0.49927583 0.34481114 0.83737046 0.5443581  0.83231837 0.5445632\n",
      " 0.8159382  0.75645787 0.82783157 0.79956543 1.0056841  0.7730881\n",
      " 0.60499203 0.8548383  0.7251176  0.63352036 0.8081018  0.569323\n",
      " 0.19801766 0.48322755 0.72735906 0.7038277  0.8922891  0.3350026\n",
      " 0.62029076 0.31736365 0.7237551  0.46263188 0.80536807 0.9770267\n",
      " 0.8503785  0.6684781  0.94025004 0.807658   0.6608147  0.8220508\n",
      " 0.9238098  0.72458124 0.7601086  0.9071682  0.8647172  0.738845\n",
      " 0.5306164  0.73734957 0.27469185 0.7606739 ]\n",
      "Reconstruction errors saved in file: dataset_1_weights_test_ndim_20_filters_32_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_1_weights_test_ndim_20_filters_32_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[20, 32]\n",
      "10000/10000 [==============================] - 3s 326us/sample\n",
      "[0.31670904 0.16470668 0.2806878  0.35042542 0.2813663  0.34307402\n",
      " 0.6327145  0.40064773 0.88994914 0.4925333  0.23349778 0.47465858\n",
      " 0.52261245 0.28313255 0.09551159 0.2843319  0.3903971  0.2918671\n",
      " 0.21245652 0.14692017 0.21922746 0.36916065 0.27699643 0.52725244\n",
      " 0.30034488 0.4913562  0.11509559 0.13477753 0.25220406 0.12508816\n",
      " 0.34723237 0.77762055 0.572824   0.18956271 0.47070515 0.45948818\n",
      " 0.5317437  0.7056645  0.45868924 0.2809767  0.14755426 0.2916505\n",
      " 0.15898304 0.31388456 0.08375202 0.5304409  0.116549   0.21818198\n",
      " 0.3574253  0.1398031  0.17487974 0.4678184  0.71030074 0.1807133\n",
      " 0.28280872 0.18557967 0.25458515 0.20876607 0.2804903  0.51533103\n",
      " 0.36515453 0.28759855 0.36218643 0.5545704  0.2616415  0.44816867\n",
      " 0.4096156  0.16948812 0.3144355  0.32849777 0.39093494 0.57183045\n",
      " 0.21949126 0.11598739 0.13282123 0.5097006  0.2279524  0.1163963\n",
      " 0.33988747 0.08641836 0.5033621  0.31891027 1.0093457  0.25449952\n",
      " 0.57849973 0.1323746  0.18284607 0.12382217 0.15010552 0.18343079\n",
      " 0.93453526 0.54960823 0.08851789 0.29149225 0.25683632 0.28175172\n",
      " 0.4615512  0.22259225 0.09277679 0.13733006]\n",
      "Reconstruction errors saved in file: dataset_1_weights_test_ndim_100_filters_32_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_1_weights_test_ndim_100_filters_32_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[100, 32]\n",
      "10000/10000 [==============================] - 4s 362us/sample\n",
      "[ 5.9244876   0.2369991   1.6180439   3.336519    0.31558582  0.99230283\n",
      "  0.68470013  0.43372488  3.9429483   4.9314194   0.3038109  10.350778\n",
      "  3.2851584   2.4174564   0.18476622  1.6594399   0.41702136  0.30947873\n",
      "  0.56724674  0.2891334   0.15628766  7.4453278   4.649104    8.02562\n",
      "  3.4919572   0.5134566   0.19662224  0.40495393  1.899623    0.32161134\n",
      "  0.36210397  1.8048801  10.488321    0.33468378  0.69007564  0.49436247\n",
      "  1.6986799   8.312348    3.2796576   0.82234764  0.26096904  1.4143635\n",
      "  0.33577812  2.3035812   0.17950927  1.3667135   0.1487802   1.6832893\n",
      "  0.40392056  0.1982358   0.16585174  0.49726295  6.6992407   0.12383363\n",
      "  0.34135446  0.16567     0.37908396  0.27972385  0.64480495  0.5477292\n",
      "  5.1785426   5.412295    0.49317425  2.394128    1.5944029   1.3290952\n",
      "  0.41708097  0.49216285  2.7287934   0.35682926  4.200645    0.6093458\n",
      "  0.1130009   0.26647192  0.24010454  0.6886421   1.2672132   0.18768834\n",
      "  0.41703975  0.15695433  0.9436791   0.3041189   9.812233    0.879533\n",
      "  6.515746    0.28759375  0.8138046   0.22730654  0.30532062  0.1378866\n",
      " 11.802656    2.0473542   0.18474285  3.331565    1.9584424   0.4447125\n",
      "  0.48186862  1.2040329   0.1301382   0.21709408]\n",
      "Reconstruction errors saved in file: dataset_1_weights_test_ndim_2_filters_64_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_1_weights_test_ndim_2_filters_64_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[2, 64]\n",
      "10000/10000 [==============================] - 4s 373us/sample\n",
      "[1.3752278  0.2339796  1.4431028  1.7143099  0.34142256 1.4001036\n",
      " 0.6628488  0.47549045 4.1888456  2.184358   0.3240951  1.8735619\n",
      " 3.3509135  1.6004196  0.17638963 1.1337168  0.45306277 0.33449972\n",
      " 0.34089094 0.27013332 0.17198832 1.4703397  1.9869188  1.8655592\n",
      " 1.8485924  0.5576909  0.19941813 0.3618672  0.57822436 0.26223794\n",
      " 0.34685794 2.5491576  3.265573   0.29345512 0.5050379  0.52388674\n",
      " 2.5590668  2.3737068  2.1043196  0.67017484 0.2524404  1.1834478\n",
      " 0.27657315 1.3484308  0.18672848 0.7092944  0.1679398  1.0884359\n",
      " 0.3977631  0.23371519 0.17992091 0.5415001  2.9142892  0.13244939\n",
      " 0.331755   0.1942776  0.30239025 0.30698726 0.5358235  0.58514017\n",
      " 1.8390468  1.216706   0.40923738 1.8998582  1.0611665  0.9111723\n",
      " 0.36684266 0.4694738  1.5695746  0.33311802 1.0208997  0.65673983\n",
      " 0.12649825 0.23860367 0.2252879  0.53534794 1.1582642  0.19203252\n",
      " 0.39925617 0.18127018 0.972473   0.29487196 2.6078305  0.45656762\n",
      " 2.327677   0.2714766  0.52294093 0.22917098 0.27764115 0.15202779\n",
      " 4.103242   0.9509819  0.18612836 1.9310809  1.4385324  0.3503398\n",
      " 0.52690053 1.2186064  0.13583213 0.23578545]\n",
      "Reconstruction errors saved in file: dataset_1_weights_test_ndim_10_filters_64_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_1_weights_test_ndim_10_filters_64_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[10, 64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 390us/sample\n",
      "[1.8309127  0.18096608 0.70348835 1.2928209  0.3190396  0.73809546\n",
      " 0.6359992  0.42890352 8.59768    3.7114453  0.28014985 3.0332932\n",
      " 4.8834705  1.1128111  0.10631524 0.59985983 0.4320231  0.30818295\n",
      " 0.34125847 0.20778026 0.17813088 3.4230225  1.9346468  3.4535565\n",
      " 1.4391791  0.5297355  0.13257177 0.22559203 0.5650491  0.1729508\n",
      " 0.35686105 2.672126   8.451789   0.22845434 0.68116325 0.48302585\n",
      " 3.509932   6.459663   2.341515   0.5484456  0.19857503 0.68727577\n",
      " 0.21081822 1.288869   0.10120583 1.6062481  0.11541747 0.50248647\n",
      " 0.39215335 0.16096953 0.1570406  0.5167445  5.7913933  0.1071445\n",
      " 0.31243303 0.17356095 0.32535464 0.24111474 0.5552551  0.5543334\n",
      " 3.691496   1.9609501  0.44459447 3.6159449  0.6032225  1.0539808\n",
      " 0.3679103  0.30148053 1.8609806  0.34437767 2.3270838  0.6195773\n",
      " 0.11286975 0.15286656 0.15073892 0.4703884  0.5882235  0.13482225\n",
      " 0.41873217 0.10982169 0.8717325  0.31381404 7.193797   0.43124753\n",
      " 8.4456415  0.20767431 0.33188793 0.14087449 0.22207975 0.13308902\n",
      " 9.59889    0.7635612  0.11000972 2.2836936  0.6460492  0.39072907\n",
      " 0.4835602  0.5016813  0.07703027 0.16999303]\n",
      "Reconstruction errors saved in file: dataset_1_weights_test_ndim_20_filters_64_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_1_weights_test_ndim_20_filters_64_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[20, 64]\n",
      "10000/10000 [==============================] - 4s 405us/sample\n",
      "[0.24962547 0.1507382  0.18823507 0.24419032 0.3175334  0.30925804\n",
      " 0.6382006  0.43299165 4.089234   0.4370874  0.27534088 0.567451\n",
      " 0.5822755  0.18961446 0.07207097 0.21458313 0.44215372 0.30660564\n",
      " 0.19132568 0.11660422 0.23619926 0.28780386 0.16458859 0.49818468\n",
      " 0.17595977 0.52734447 0.10935473 0.07303649 0.20346263 0.10096399\n",
      " 0.32761315 1.4796628  1.4677786  0.16425794 0.5000148  0.4693823\n",
      " 0.58541256 2.2547538  0.3772164  0.15784582 0.12434512 0.2033183\n",
      " 0.13378279 0.18541104 0.07357776 0.5034103  0.11813685 0.1528786\n",
      " 0.3979286  0.15094976 0.16285954 0.52303207 1.9534086  0.12489259\n",
      " 0.30594984 0.1920636  0.20661709 0.22287723 0.26073566 0.53278434\n",
      " 0.29210258 0.21920255 0.31845024 0.6187363  0.16886513 0.36184126\n",
      " 0.4282013  0.13344862 0.25924975 0.32309484 0.3110661  0.60623884\n",
      " 0.15380973 0.06648061 0.13004144 0.46416456 0.16129623 0.10709134\n",
      " 0.3303153  0.0808839  0.47084716 0.3017704  2.5296903  0.10815706\n",
      " 0.92333543 0.10829588 0.12083972 0.11553297 0.12886457 0.1588315\n",
      " 4.137734   0.4948886  0.07797769 0.17067201 0.14613308 0.25239617\n",
      " 0.48873135 0.16421992 0.06551027 0.14899695]\n",
      "Reconstruction errors saved in file: dataset_1_weights_test_ndim_100_filters_64_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_1_weights_test_ndim_100_filters_64_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[100, 64]\n",
      "10000/10000 [==============================] - 5s 483us/sample\n",
      "[6.82084656e+01 3.49623263e-01 1.54266327e+02 8.32180786e+01\n",
      " 3.66433144e-01 1.32507660e+02 3.37426186e+01 3.08951092e+01\n",
      " 1.42204332e+01 5.10957680e+01 3.26932937e-01 5.24218826e+01\n",
      " 5.54296837e+01 1.19481590e+02 3.11930597e-01 8.00194397e+01\n",
      " 4.71831083e-01 3.90739381e-01 5.67386017e+01 5.63812017e+00\n",
      " 2.09789753e-01 7.56029587e+01 1.19443657e+02 9.91082611e+01\n",
      " 8.52552948e+01 5.05228138e+00 3.14659745e-01 2.41834946e+02\n",
      " 1.15860138e+02 1.51789017e+02 3.99515033e-01 9.27115097e+01\n",
      " 6.47296829e+01 6.56903076e+01 5.05307388e+01 2.15397701e+01\n",
      " 8.32059402e+01 1.68691120e+01 1.12660744e+02 4.89403000e+01\n",
      " 4.84843671e-01 1.59786972e+02 1.29950897e+02 1.47610596e+02\n",
      " 3.05348426e-01 3.50252266e+01 2.63992518e-01 1.19624359e+02\n",
      " 3.38880005e+01 3.26970428e-01 2.59802163e-01 1.41051502e+01\n",
      " 2.31061325e+01 1.82355955e-01 2.70089779e+01 2.60742128e-01\n",
      " 7.51551569e-01 3.10961843e-01 5.62344093e+01 8.59904575e+00\n",
      " 6.29513474e+01 8.62787857e+01 6.38656120e+01 2.94744816e+01\n",
      " 1.67662537e+02 4.67253151e+01 2.46253834e+01 1.57385452e+02\n",
      " 4.28508301e+01 6.47777319e-01 4.89319878e+01 1.46048155e+01\n",
      " 1.61873266e-01 7.94888153e+01 9.80368710e+00 2.57766876e+01\n",
      " 1.49287445e+02 3.16586733e-01 1.57857406e+00 3.01812530e-01\n",
      " 3.37655525e+01 4.81990188e-01 6.72482147e+01 7.67652206e+01\n",
      " 4.55391579e+01 3.27564125e+01 1.84905060e+02 3.29037845e-01\n",
      " 2.02398529e+01 2.08084449e-01 3.09965363e+01 2.73339291e+01\n",
      " 3.16851616e-01 1.29570984e+02 1.15179245e+02 4.27052994e+01\n",
      " 1.77448521e+01 9.48583603e+01 2.36920297e-01 3.46894294e-01]\n",
      "Reconstruction errors saved in file: dataset_1_weights_test_ndim_2_filters_128_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_1_weights_test_ndim_2_filters_128_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[2, 128]\n",
      "10000/10000 [==============================] - 5s 508us/sample\n",
      "[ 33.831112     0.3256902   59.93999     37.75169      0.4203643\n",
      "  71.25406     19.09243      0.50008655  12.300746    23.182028\n",
      "   0.41313562  26.8671      29.000185    57.247124     0.29782787\n",
      "  38.27029      0.4979817    0.39877662  75.35032      0.3339425\n",
      "   0.21540892  37.412083    57.525883    58.83841     39.602493\n",
      "   0.5482197    0.30536494  88.71752     55.442154     6.519369\n",
      "   0.3712008   59.53064     34.94263      9.197292    66.93383\n",
      "   0.4363456   41.768444    10.329676    52.420918    87.91923\n",
      "   0.29724136  62.14433      2.013168    69.16657      0.30719337\n",
      "  17.184969     0.25178596  63.780956     0.54533064   0.32614306\n",
      "   0.25347802   0.56228346  14.057199     0.18160081  10.104778\n",
      "   0.2547685    0.32675323   0.41032827  24.530058     0.50646365\n",
      "  29.627317    38.35578      1.083313    14.967704    73.28952\n",
      "  23.132841    23.809872    95.23161     33.73496      0.3597243\n",
      "  25.716953     0.58166003   0.16008364   0.30251658   0.24705201\n",
      "  10.8064      66.94519      0.28854498   0.42456838   0.28014913\n",
      "  15.678196     0.31996545  39.639816   113.21252     21.953835\n",
      "   0.4068049  108.51651      0.33044127   1.6819274    0.20602295\n",
      "  17.464008    12.808008     0.32203     61.266113    49.641838\n",
      "   2.624274     4.4787397   37.896202     0.22212401   0.33319014]\n",
      "Reconstruction errors saved in file: dataset_1_weights_test_ndim_10_filters_128_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_1_weights_test_ndim_10_filters_128_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[10, 128]\n",
      "10000/10000 [==============================] - 5s 526us/sample\n",
      "[5.67715416e+01 1.67795226e-01 1.56919205e+02 8.13691406e+01\n",
      " 3.26658845e-01 7.07507324e+01 7.05414951e-01 4.46640283e-01\n",
      " 1.61744461e+01 4.87565727e+01 2.90948391e-01 5.11182404e+01\n",
      " 5.33461227e+01 1.15589096e+02 1.19948521e-01 8.08494492e+01\n",
      " 4.36844051e-01 3.08346570e-01 3.81145897e+01 2.45710790e-01\n",
      " 1.71790168e-01 7.31981354e+01 1.19142784e+02 1.06325180e+02\n",
      " 8.06616516e+01 5.40042400e-01 1.51121914e-01 3.04780304e-01\n",
      " 1.11645714e+02 1.93002626e-01 3.98678571e-01 4.48684311e+01\n",
      " 5.74901199e+01 2.58989036e-01 3.83226323e+00 4.84978288e-01\n",
      " 8.06237717e+01 1.43902025e+01 1.09253265e+02 7.94255905e+01\n",
      " 2.28226632e-01 1.56458450e+02 2.13769168e-01 1.39068924e+02\n",
      " 1.24097854e-01 3.33273888e+01 1.20738730e-01 1.28233932e+02\n",
      " 4.04041886e-01 1.83378875e-01 1.51254684e-01 5.31578422e-01\n",
      " 2.10436802e+01 1.21412970e-01 2.87078530e-01 1.61634088e-01\n",
      " 6.46187544e-01 2.54742533e-01 3.36735840e+01 5.32215178e-01\n",
      " 6.27280083e+01 8.44992294e+01 4.61655617e+00 2.99853058e+01\n",
      " 1.64498611e+02 4.79220390e+01 4.55669355e+00 1.89421368e+01\n",
      " 4.77503319e+01 4.00754988e-01 5.61384125e+01 6.23954773e-01\n",
      " 1.00763753e-01 1.93017185e-01 1.77405179e-01 2.44931469e+01\n",
      " 1.39349899e+02 1.22458614e-01 4.96406168e-01 1.13215096e-01\n",
      " 3.09488564e+01 3.60929400e-01 5.75701866e+01 9.56416779e+01\n",
      " 4.88933830e+01 2.26741478e-01 9.54570618e+01 1.63662925e-01\n",
      " 2.51322389e-01 1.26800910e-01 2.75129776e+01 2.67272644e+01\n",
      " 1.20903797e-01 1.32995712e+02 1.20053009e+02 8.10442257e+00\n",
      " 4.35595512e-01 8.98498306e+01 7.76805803e-02 1.78218827e-01]\n",
      "Reconstruction errors saved in file: dataset_1_weights_test_ndim_20_filters_128_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_1_weights_test_ndim_20_filters_128_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[20, 128]\n",
      "10000/10000 [==============================] - 5s 547us/sample\n",
      "[2.89538711e-01 1.38216883e-01 1.29730061e-01 2.57054746e-01\n",
      " 3.34266424e-01 3.74550968e-01 8.65199509e+01 7.80969262e-01\n",
      " 2.85869171e+02 1.03226805e+00 2.04361379e-01 4.32249718e+01\n",
      " 1.52956331e+00 1.58382326e-01 7.45666400e-02 1.98924810e-01\n",
      " 4.59168792e-01 4.02319789e-01 2.26980448e-01 1.38158426e-01\n",
      " 2.58162171e-01 5.13105333e-01 1.68466821e-01 1.93424439e+00\n",
      " 1.78383425e-01 4.36659431e+00 1.13665819e-01 6.09641969e-02\n",
      " 2.46704668e-01 1.08986445e-01 2.73943722e-01 4.96652079e+00\n",
      " 2.38167267e+01 1.69055775e-01 6.18217766e-01 5.96120894e-01\n",
      " 1.63352144e+00 1.67847519e+02 3.98767889e-01 1.63722828e-01\n",
      " 1.11021541e-01 1.92967236e-01 1.35014042e-01 2.33318493e-01\n",
      " 7.86868110e-02 2.24640679e+00 1.43102124e-01 1.38890713e-01\n",
      " 4.37907010e-01 1.67386189e-01 1.66403219e-01 8.63259912e-01\n",
      " 3.60074158e+02 1.48241282e-01 3.16661447e-01 1.93692550e-01\n",
      " 1.82896093e-01 2.20164299e-01 2.21476406e-01 5.78859687e-01\n",
      " 4.52165306e-01 3.10810179e-01 2.33076304e-01 1.79596756e+02\n",
      " 9.02616307e-02 8.63763213e-01 4.94955301e-01 1.09666802e-01\n",
      " 4.53702807e-01 2.82143295e-01 1.09681451e+00 1.19825387e+00\n",
      " 1.40046149e-01 7.01068938e-02 1.28312632e-01 1.82142138e+00\n",
      " 1.36460811e-01 9.10202339e-02 3.29298705e-01 8.22052434e-02\n",
      " 1.54186702e+00 3.14197600e-01 3.36139526e+02 1.33999676e-01\n",
      " 2.15644424e+02 9.20878574e-02 8.17387700e-02 1.25901282e-01\n",
      " 1.22025408e-01 1.73139468e-01 4.79922668e+02 6.79212494e+01\n",
      " 7.15311021e-02 1.80193678e-01 1.11313574e-01 3.18227351e-01\n",
      " 5.53688824e-01 1.67755648e-01 8.33018571e-02 1.10445291e-01]\n",
      "Reconstruction errors saved in file: dataset_1_weights_test_ndim_100_filters_128_recon_error.npy\n",
      "Reconstructed Images saved in file: dataset_1_weights_test_ndim_100_filters_128_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[100, 128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26032/26032 [==============================] - 7s 283us/sample\n"
     ]
    }
   ],
   "source": [
    "#Reconstruction block\n",
    "import numpy as np\n",
    "import os\n",
    "from VAE_reconstruct import reconstruct_images\n",
    "\n",
    "\n",
    "dataset_prep = np.asarray([prepare_dataset_mnist, prepare_dataset_fashion_mnist, prepare_dataset_mat])\n",
    "model_hyperparameters = [[2,32],[10,32],[20,32],[100,32],\n",
    "                         [2,64],[10,64],[20,64],[100,64],\n",
    "                         [2,128],[10,128],[20,128],[100,128]]\n",
    "\n",
    "\n",
    "def reconstruct_all_datasets(add_list_of_datasets): # seeks folders in current working directory, enters them and performs reconstructions in the folder\n",
    "    #create names for weights_test\n",
    "    weight_names_list = []\n",
    "    for i in range(len(dataset_prep)):\n",
    "        filename = 'dataset_'+str(i)+'_run_initial'\n",
    "        weight_names_list.append(filename)\n",
    "    weight_names_list = np.array(weight_names_list)\n",
    "    \n",
    "    return_here_path = os.getcwd()\n",
    "    for i in range(len(dataset_prep)):\n",
    "        os.chdir(return_here_path)\n",
    "        \n",
    "        _, X_test, _, _ = dataset_prep[i]() #cycle through each function to create dataset\n",
    "        weights_name_dataset = weight_names_list[i] #create basename for folder to be created for a particular dataset\n",
    "        \n",
    "        #automate folder creation for each dataset\n",
    "        path_dataset = os.path.abspath(os.getcwd())+'\\\\'+str(weights_name_dataset)\n",
    "        if not os.path.exists(path_dataset):\n",
    "            os.makedirs(path_dataset)\n",
    "        \n",
    "        for j in model_hyperparameters:\n",
    "            os.chdir(path_dataset) \n",
    "            weights_name = weights_name_dataset+'_ndim_'+str(j[0])+'_filters_'+str(j[1])\n",
    "            reconstruct_images(X_test, dim_representation=j[0], b_f=j[1], filename_weights= weights_name)\n",
    "            print('Reconstructing model with hyperparams:' + str(j))\n",
    "            \n",
    "    os.chdir(return_here_path) #return to working directory of this script\n",
    "    return\n",
    "\n",
    "reconstruct_all_datasets(dataset_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing model with hyperparams:[100, 128]\n",
      "Reconstructing model with hyperparams:[100, 32]\n",
      "Reconstructing model with hyperparams:[100, 64]\n",
      "Reconstructing model with hyperparams:[10, 64]\n",
      "Reconstructing model with hyperparams:[20, 32]\n",
      "Reconstructing model with hyperparams:[20, 64]\n",
      "Reconstructing model with hyperparams:[2, 32]\n",
      "Reconstructing model with hyperparams:[2, 64]\n"
     ]
    }
   ],
   "source": [
    "#Reconstruction block. FULLY FUNCTIONAL SINCE 19/02/2020. Memory problems after 2 folders though\n",
    "import numpy as np\n",
    "import os\n",
    "from VAE_reconstruct import reconstruct_images\n",
    "from dataset_unpacking_utility import prepare_dataset_mat, prepare_dataset_fashion_mnist, prepare_dataset_mnist\n",
    "\n",
    "dataset_prep = np.asarray([prepare_dataset_mnist, prepare_dataset_fashion_mnist, prepare_dataset_mat])\n",
    "model_hyperparameters = [[2,32],[10,32],[20,32],[100,32],\n",
    "                         [2,64],[10,64],[20,64],[100,64],\n",
    "                         [2,128],[10,128],[20,128],[100,128]]\n",
    "\n",
    "def reconstruct_all_datasets(add_list_of_datasets): # seeks folders in current working directory, enters them and performs reconstructions in the folder\n",
    "    #grab npy \n",
    "    import os\n",
    "    return_here_path = os.getcwd()\n",
    "    \n",
    "    \n",
    "    reconstruction_errors_filepaths = []\n",
    "    for root, dirs, files in os.walk(return_here_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".h5\"):\n",
    "                #if 'mnist' in file:\n",
    "                #    os.chdir(root)\n",
    "                #    _, X_test, _, _ = dataset_prep[0]() #cycle through each function to create dataset\n",
    "#\n",
    "                #    for j in model_hyperparameters:\n",
    "                #        if \"ndim_\"+str(j[0])+\"_filters_\"+str(j[1]) in file:\n",
    "                #            filename_weights = 'C:\\\\Users\\\\31687\\\\Desktop\\\\VAE-SVHN-master\\\\Automated\\\\dataset_mnist_run_initial\\\\'+file[:-3]\n",
    "                #            reconstruct_images(X_test, dim_representation=j[0], b_f=j[1], filename_weights= filename_weights)\n",
    "                #            print('Reconstructing model with hyperparams:' + str(j))\n",
    "                #        \n",
    "                #if 'fashion' in file:\n",
    "                #    _, X_test, _, _ = dataset_prep[1]() #cycle through each function to create dataset\n",
    "                #    \n",
    "                #    os.chdir(root)\n",
    "                #    for j in model_hyperparameters:\n",
    "                #        if \"ndim_\"+str(j[0])+\"_filters_\"+str(j[1]) in file:\n",
    "                #            filename_weights = 'C:\\\\Users\\\\31687\\\\Desktop\\\\VAE-SVHN-master\\\\Automated\\\\dataset_fashion_run_initial\\\\'+file[:-3]\n",
    "                #            #reconstruct_images(X_test, dim_representation=j[0], b_f=j[1], filename_weights= filename_weights)\n",
    "                #            print('Reconstructing model with hyperparams:' + str(j))\n",
    "                \n",
    "                if 'svhn' in file:\n",
    "                    \n",
    "                    _, X_test, _, _ = dataset_prep[2]() #cycle through each function to create dataset\n",
    "                    del _\n",
    "                    \n",
    "                    os.chdir(root)\n",
    "                    for j in model_hyperparameters:\n",
    "                        if \"ndim_\"+str(j[0])+\"_filters_\"+str(j[1]) in file:\n",
    "                            filename_weights = 'C:\\\\Users\\\\31687\\\\Desktop\\\\VAE-SVHN-master\\\\Automated\\\\dataset_svhn_run_initial\\\\'+file[:-3]\n",
    "                            #reconstruct_images(X_test, dim_representation=j[0], b_f=j[1], filename_weights= filename_weights)\n",
    "                            print('Reconstructing model with hyperparams:' + str(j))               \n",
    "            \n",
    "    os.chdir(return_here_path) #return to working directory of this script\n",
    "    return\n",
    "\n",
    "reconstruct_all_datasets(dataset_prep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\31687\\\\Desktop\\\\VAE-SVHN-master\\\\Automated\\\\')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'automated_draw.ipynb',\n",
       " 'automated_recon_error_analysis.ipynb',\n",
       " 'checkpoint',\n",
       " 'CNN_VAE_template.py',\n",
       " 'dataset_fashion_run_initial',\n",
       " 'dataset_mnist_run_initial',\n",
       " 'dataset_svhn_run_initial',\n",
       " 'dataset_unpacking_utility.py',\n",
       " 'DEMO_Single_model_Trainer.ipynb',\n",
       " 'Exclude_one_label_0.data-00000-of-00002',\n",
       " 'Exclude_one_label_0.data-00001-of-00002',\n",
       " 'Exclude_one_label_0.h5',\n",
       " 'Exclude_one_label_0.index',\n",
       " 'Exclude_one_label_0_reconstructed_images.npy',\n",
       " 'Exclude_one_label_0_recon_error.npy',\n",
       " 'Label_index_utility.py',\n",
       " 'paralleltraining.ipynb',\n",
       " 'reconstruction_error_analysis.ipynb',\n",
       " 'reconstruct_models.py',\n",
       " 'SVHN_pipeline_weights_test.data-00000-of-00002',\n",
       " 'SVHN_pipeline_weights_test.data-00001-of-00002',\n",
       " 'SVHN_pipeline_weights_test.h5',\n",
       " 'SVHN_pipeline_weights_test.index',\n",
       " 'SVHN_pipeline_weights_test_reconstructed_images.npy',\n",
       " 'SVHN_pipeline_weights_test_recon_error.npy',\n",
       " 'train_all_models.py',\n",
       " 'train_all_models_fashion.py',\n",
       " 'train_all_models_svhn.py',\n",
       " 'train_CNN_VAE.py',\n",
       " 'train_CNN_VAE_create_folders.py',\n",
       " 'VAE_reconstruct.py',\n",
       " 'VAE_utilities.py',\n",
       " 'visualizing_images.py',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26032/26032 [==============================] - 7s 267us/sample\n",
      "[4.39143920e+07 1.64528728e-01 2.14108795e-01 1.87201291e-01\n",
      " 1.46724626e-01 2.22902179e+00 3.58268440e+07 3.86355579e-01\n",
      " 1.59779668e-01 2.39649042e-01 2.43761882e-01 3.60699776e+08\n",
      " 5.98622592e+08 1.24839574e-01 1.44867584e-01 1.38057068e-01\n",
      " 4.56236675e-02 3.96290980e-02 1.04024485e-01 1.73903003e-01\n",
      " 3.03956985e-01 3.11443865e-01 6.39147043e-01 3.51966572e+00\n",
      " 1.51858956e-01 1.64852351e-01 3.58884192e+00 3.81827744e+08\n",
      " 5.92622719e+01 4.35177863e-01 3.49105775e-01 3.14743919e+01\n",
      " 1.12969732e+00 7.15544641e-01 5.35793900e-01 9.72797722e-02\n",
      " 1.33224562e-01 1.10268570e-01 1.36396770e+07 5.28203154e+00\n",
      " 5.43910122e+00 5.67190160e+07 4.64839750e+05 3.71370286e-01\n",
      " 1.79891472e+08 5.28559424e+08 1.73200414e-01 1.52073598e+00\n",
      " 9.12883937e-01 6.87505007e-01 8.00728381e-01 6.68464184e-01\n",
      " 5.70766270e-01 1.65512443e-01 1.66188613e-01 3.08762491e-01\n",
      " 2.96464175e-01 1.72178173e+00 2.11319355e+04 1.99758694e-01\n",
      " 8.25923085e-02 7.42447302e-02 2.72321300e+07 2.29364080e+07\n",
      " 1.28377776e+08 1.33490096e+08 1.94583100e+07 2.04935620e+07\n",
      " 1.87008381e-01 1.42016888e-01 3.84200990e-01 2.90504873e-01\n",
      " 1.73617229e-01 5.11200096e+08 3.34370880e+08 3.63042528e+08\n",
      " 3.30626488e-01 4.64633614e-01 3.24953705e-01 6.94433823e-02\n",
      " 7.77232796e-02 1.93478718e-01 1.58357158e-01 1.77071169e-01\n",
      " 1.81227729e-01 3.90436500e-02 4.62913401e-02 1.48636088e-01\n",
      " 1.92917079e-01 1.29441190e+00 3.24928731e-01 1.56560257e-01\n",
      " 1.66718423e-01 1.72743440e-01 1.67620957e-01 7.76546672e-02\n",
      " 7.98015669e-02 4.80932040e+07 7.64566480e+07 3.75266836e+04]\n",
      "Reconstruction errors saved in file: svhn_SVHN_ndim_10_filters_64_recon_error.npy\n",
      "Reconstructed Images saved in file: svhn_SVHN_ndim_10_filters_64_reconstructed_images.npy\n",
      "Reconstructing model with hyperparams:[10, 64]\n",
      "26032/26032 [==============================] - 8s 317us/sample\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Reconstruction block. FULLY FUNCTIONAL SINCE 19/02/2020. Memory problems after 2 folders though\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from VAE_reconstruct import reconstruct_images\n",
    "from dataset_unpacking_utility import prepare_dataset_mat\n",
    "\n",
    "model_hyperparameters = [#[2,32],[10,32],[20,32],\n",
    "                         #[2,64],[10,64],[20,64],\n",
    "                         [2,128],[10,128],[20,128]\n",
    "                        ]\n",
    "dataset_prep = np.asarray([prepare_dataset_mat])\n",
    "\n",
    "def reconstruct_all_datasets(add_list_of_datasets): # seeks folders in current working directory, enters them and performs reconstructions in the folder\n",
    "    #grab npy \n",
    "    import os\n",
    "    path = \"C:\\\\Users\\\\31687\\\\Desktop\\\\VAE-SVHN-master\\\\Automated\\\\dataset_svhn_run_initial\"\n",
    "    _, X_test, _, _ = dataset_prep[0]() #cycle through each function to create dataset\n",
    "    \n",
    "    del _\n",
    "    os.chdir(path)\n",
    "    \n",
    "    reconstruction_errors_filepaths = []\n",
    "    for file in os.listdir():\n",
    "        if file.endswith(\".h5\"):\n",
    "            #if 'mnist' in file:\n",
    "            #    print(root)\n",
    "            #    os.chdir(root)\n",
    "            #    print(os.getcwd())\n",
    "            #    _, X_test, _, _ = dataset_prep[0]() #cycle through each function to create dataset\n",
    "            #    \n",
    "            #    \n",
    "            #    for j in model_hyperparameters:\n",
    "            #        if \"ndim_\"+str(j[0])+\"_filters_\"+str(j[1]) in file:\n",
    "            #            reconstruct_images(X_test, dim_representation=j[0], b_f=j[1], filename_weights= file[:-3])\n",
    "            #            print('Reconstructing model with hyperparams:' + str(j))\n",
    "            #        \n",
    "            #if 'fashion' in file:\n",
    "            #    _, X_test, _, _ = dataset_prep[1]() #cycle through each function to create dataset\n",
    "            #    \n",
    "            #    os.chdir(root)\n",
    "            #    for j in model_hyperparameters:\n",
    "        \n",
    "            #        if \"ndim_\"+str(j[0])+\"_filters_\"+str(j[1]) in file:\n",
    "            #            reconstruct_images(X_test, dim_representation=j[0], b_f=j[1], filename_weights= file[:-3])\n",
    "            #            print('Reconstructing model with hyperparams:' + str(j))\n",
    "            \n",
    "            if 'svhn' in file:\n",
    "                \n",
    "                os.chdir(path)\n",
    "                for j in model_hyperparameters:\n",
    "                    if \"ndim_\"+str(j[0])+\"_filters_\"+str(j[1]) in file:\n",
    "                        reconstruct_images(X_test, dim_representation=j[0], b_f=j[1], filename_weights= file[:-3])\n",
    "                        print('Reconstructing model with hyperparams:' + str(j))               \n",
    "            \n",
    "    os.chdir(path) #return to working directory of this script\n",
    "    return\n",
    "\n",
    "reconstruct_all_datasets(dataset_prep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataset_unpacking_utility import prepare_dataset_mat, prepare_dataset_fashion_mnist, prepare_dataset_mnist\n",
    "\n",
    "_, X_test, _, y_test = prepare_dataset_mnist()\n",
    "reconstructed_images = np.load('SVHN_pipeline_weights_test_reconstructed_images.npy')\n",
    "\n",
    "from visualizing_images import visualize_images #does pyplot and makes a grid of data\n",
    "\n",
    "print(visualize_images(X_test, y_test, 3))\n",
    "print(visualize_images(reconstructed_images, y_test, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
